from flask import Blueprint, request, jsonify, current_app
from werkzeug.utils import secure_filename
import os
import uuid
import sqlite3
import json
import markdown
from datetime import datetime
from werkzeug.security import check_password_hash
import tempfile
import re
from socket_utils import notify_page_refresh

notifications_bp = Blueprint('notifications', __name__, url_prefix='/api/notifications')

# å…è®¸çš„æ–‡æ¡£æ–‡ä»¶æ‰©å±•åï¼ˆåªä¿ç•™Markdownï¼‰
ALLOWED_DOC_EXTENSIONS = {'md', 'markdown'}

def allowed_doc_file(filename):
    if '.' not in filename:
        return False
    file_parts = filename.rsplit('.', 1)
    if len(file_parts) < 2:
        return False
    return file_parts[1].lower() in ALLOWED_DOC_EXTENSIONS

def ensure_upload_dir():
    """ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨"""
    upload_dir = os.path.join(current_app.root_path, 'static', 'uploads', 'notifications')
    if not os.path.exists(upload_dir):
        os.makedirs(upload_dir)
    return upload_dir

def get_db():
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn = sqlite3.connect(current_app.config.get('DATABASE', 'acm_lab.db'))
    conn.row_factory = sqlite3.Row
    return conn

def require_auth():
    """éªŒè¯ç”¨æˆ·æƒé™"""
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥æœ‰å®Œæ•´çš„æƒé™éªŒè¯
    return True

def markdown_to_html(content):
    """å°†Markdownå†…å®¹è½¬æ¢ä¸ºHTML"""
    try:
        import re
        
        # é¢„å¤„ç†ï¼šå¤„ç†å›¾ç‰‡é“¾æ¥ï¼Œç¡®ä¿ç›¸å¯¹è·¯å¾„æ­£ç¡®
        content = preprocess_markdown_images(content)
        
        # é…ç½®markdownæ‰©å±•
        md = markdown.Markdown(extensions=[
            'extra',  # æ”¯æŒè¡¨æ ¼ã€ä»£ç å—ç­‰
            'codehilite',  # ä»£ç é«˜äº®
            'toc',  # ç›®å½•ç”Ÿæˆ
            'nl2br',  # æ¢è¡Œè½¬æ¢
            'tables',  # è¡¨æ ¼æ”¯æŒ
            'fenced_code',  # ä»£ç å—æ”¯æŒ
            'attr_list',  # å±æ€§åˆ—è¡¨æ”¯æŒ
        ], extension_configs={
            'codehilite': {
                'css_class': 'highlight',
                'use_pygments': False,
                'noclasses': True
            },
            'toc': {
                'anchorlink': True,
                'title': 'ç›®å½•'
            }
        })
        
        html_content = md.convert(content)
        
        # ä¼˜åŒ–HTMLå†…å®¹
        html_content = optimize_html_content(html_content)
        
        return html_content
    except Exception as e:
        print(f"Markdownè½¬HTMLé”™è¯¯: {e}")
        return content

def preprocess_markdown_images(content):
    """é¢„å¤„ç†markdownä¸­çš„å›¾ç‰‡é“¾æ¥"""
    import re
    
    # å¤„ç†ç›¸å¯¹è·¯å¾„çš„å›¾ç‰‡ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
    def replace_image(match):
        alt_text = match.group(1)
        image_path = match.group(2)
        title = match.group(3) if match.group(3) else ""
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ä¸”ä¸æ˜¯ä»¥/staticå¼€å¤´ï¼Œæ·»åŠ staticè·¯å¾„å‰ç¼€
        if not image_path.startswith(('http://', 'https://', '/static/', 'data:')):
            if image_path.startswith('uploads/'):
                image_path = f'/static/{image_path}'
            elif not image_path.startswith('/'):
                image_path = f'/static/uploads/notifications/images/{image_path}'
        
        # æ·»åŠ å›¾ç‰‡çš„CSSç±»å’Œæ‡’åŠ è½½å±æ€§
        if title:
            return f'![{alt_text}]({image_path} "{title}"){{.responsive-image loading="lazy"}}'
        else:
            return f'![{alt_text}]({image_path}){{.responsive-image loading="lazy"}}'
    
    # åŒ¹é…markdownå›¾ç‰‡è¯­æ³•ï¼š![alt](src "title")
    pattern = r'!\[([^\]]*)\]\(([^\)]+?)(?:\s+"([^"]*)")?\)'
    content = re.sub(pattern, replace_image, content)
    
    return content

def optimize_html_content(html_content):
    """ä¼˜åŒ–HTMLå†…å®¹çš„æ’ç‰ˆå’Œæ ·å¼"""
    import re
    
    # ä¸ºæ ‡é¢˜æ·»åŠ é”šç‚¹
    def add_header_anchors(match):
        level = len(match.group(1))
        content = match.group(2)
        anchor_id = re.sub(r'[^\w\u4e00-\u9fff]+', '-', content).strip('-').lower()
        return f'<h{level} id="{anchor_id}">{content}</h{level}>'
    
    html_content = re.sub(r'<h([1-6])>(.*?)</h[1-6]>', add_header_anchors, html_content)
    
    # ä¸ºè¡¨æ ¼æ·»åŠ å“åº”å¼åŒ…è£…
    html_content = re.sub(
        r'<table>', 
        '<div class="table-responsive"><table class="table table-striped">', 
        html_content
    )
    html_content = re.sub(r'</table>', '</table></div>', html_content)
    
    # ä¸ºä»£ç å—æ·»åŠ å¤åˆ¶æŒ‰é’®å®¹å™¨
    html_content = re.sub(
        r'<pre><code(.*?)>', 
        r'<div class="code-block-container"><pre><code\1>', 
        html_content
    )
    html_content = re.sub(r'</code></pre>', '</code></pre></div>', html_content)
    
    # ä¸ºå›¾ç‰‡æ·»åŠ æ‡’åŠ è½½å’Œç¯ç®±æ•ˆæœ
    def enhance_image_tag(match):
        before_src = match.group(1)
        src = match.group(2)
        after_src = match.group(3)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è¿™äº›å±æ€§
        full_tag = f'<img{before_src}src="{src}"{after_src}>'
        
        # å¦‚æœæ²¡æœ‰loadingå±æ€§ï¼Œæ·»åŠ å®ƒ
        if 'loading=' not in full_tag:
            after_src += ' loading="lazy"'
        
        # å¦‚æœæ²¡æœ‰responsive-imageç±»ï¼Œæ·»åŠ å®ƒ
        if 'responsive-image' not in full_tag:
            if 'class=' in full_tag:
                # å¦‚æœå·²æœ‰classå±æ€§ï¼Œæ·»åŠ åˆ°ç°æœ‰classä¸­
                after_src = re.sub(r'class="([^"]*)"', r'class="\1 responsive-image"', after_src)
            else:
                # å¦‚æœæ²¡æœ‰classå±æ€§ï¼Œæ·»åŠ æ–°çš„class
                after_src += ' class="responsive-image"'
        
        # å¦‚æœæ²¡æœ‰onclickå±æ€§ï¼Œæ·»åŠ å®ƒ
        if 'onclick=' not in full_tag:
            after_src += ' onclick="openImageModal(this)"'
        
        # å¦‚æœæ²¡æœ‰cursoræ ·å¼ï¼Œæ·»åŠ å®ƒ
        if 'cursor:' not in full_tag:
            if 'style=' in full_tag:
                # å¦‚æœå·²æœ‰styleå±æ€§ï¼Œæ·»åŠ åˆ°ç°æœ‰styleä¸­
                after_src = re.sub(r'style="([^"]*)"', r'style="\1; cursor: pointer;"', after_src)
            else:
                # å¦‚æœæ²¡æœ‰styleå±æ€§ï¼Œæ·»åŠ æ–°çš„style
                after_src += ' style="cursor: pointer;"'
        
        return f'<img{before_src}src="{src}"{after_src}>'
    
    html_content = re.sub(
        r'<img([^>]*?)src="([^"]*?)"([^>]*?)>', 
        enhance_image_tag, 
        html_content
    )
    
    # ä¸ºå¼•ç”¨å—æ·»åŠ æ ·å¼ç±»
    html_content = re.sub(r'<blockquote>', '<blockquote class="blockquote">', html_content)
    
    # å¤„ç†æ®µè½é—´è·
    html_content = re.sub(r'<p></p>', '', html_content)
    
    return html_content

@notifications_bp.route('/frontend/activities', methods=['GET'])
def get_frontend_activities():
    """è·å–å‰ç«¯æ˜¾ç¤ºçš„å®éªŒå®¤åŠ¨æ€æ´»åŠ¨"""
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨ Vercel ç¯å¢ƒä¸­
        if os.environ.get('VERCEL'):
            # Vercel ç¯å¢ƒï¼šè¿”å›Mockæ•°æ®
            mock_activities = [
                {
                    'id': 1,
                    'title': 'å®éªŒå®¤å›¢é˜Ÿåœ¨ICML 2024ä¼šè®®å‘è¡¨é‡è¦è®ºæ–‡',
                    'excerpt': 'æˆ‘ä»¬çš„ç ”ç©¶å›¢é˜Ÿåœ¨æœºå™¨å­¦ä¹ é¡¶çº§ä¼šè®®ICML 2024ä¸Šå‘è¡¨äº†å…³äº"æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„åº”ç”¨"çš„é‡è¦è®ºæ–‡ï¼Œè¯¥æˆæœåœ¨æ™ºèƒ½ä½“åä½œé¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚',
                    'formatted_date': '2024å¹´8æœˆ15æ—¥',
                    'date': '2024-08-15',
                    'type': 'research',
                    'status': 'published'
                },
                {
                    'id': 2,
                    'title': 'ç¬¬åå±ŠACMç¨‹åºè®¾è®¡ç«èµ›æ ¡å†…é€‰æ‹”èµ›æˆåŠŸä¸¾åŠ',
                    'excerpt': 'å®éªŒå®¤æˆåŠŸä¸¾åŠäº†ç¬¬åå±ŠACMç¨‹åºè®¾è®¡ç«èµ›æ ¡å†…é€‰æ‹”èµ›ï¼Œå…±æœ‰æ¥è‡ªå…¨æ ¡çš„200ä½™åå­¦ç”Ÿå‚åŠ ã€‚ç»è¿‡æ¿€çƒˆè§’é€ï¼Œæœ€ç»ˆé€‰å‡º15åä¼˜ç§€é€‰æ‰‹ç»„æˆæ ¡é˜Ÿå‚åŠ åŒºåŸŸèµ›ã€‚',
                    'formatted_date': '2024å¹´7æœˆ20æ—¥',
                    'date': '2024-07-20',
                    'type': 'competition',
                    'status': 'published'
                },
                {
                    'id': 3,
                    'title': 'å®éªŒå®¤ä¸åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸ç­¾ç½²äº§å­¦ç ”åˆä½œåè®®',
                    'excerpt': 'ä¸ºæ¨è¿›äº§å­¦ç ”æ·±åº¦èåˆï¼Œå®éªŒå®¤ä¸åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸æ­£å¼ç­¾ç½²åˆä½œåè®®ï¼Œå°†åœ¨äººå·¥æ™ºèƒ½ç®—æ³•ä¼˜åŒ–ã€5Gé€šä¿¡æŠ€æœ¯ç­‰é¢†åŸŸå¼€å±•æ·±åº¦åˆä½œï¼Œå…±åŒåŸ¹å…»é«˜ç«¯æŠ€æœ¯äººæ‰ã€‚',
                    'formatted_date': '2024å¹´6æœˆ30æ—¥',
                    'date': '2024-06-30',
                    'type': 'cooperation',
                    'status': 'published'
                },
                {
                    'id': 4,
                    'title': 'æš‘æœŸç®—æ³•è®­ç»ƒè¥åœ†æ»¡ç»“æŸ',
                    'excerpt': 'ä¸ºæœŸå››å‘¨çš„æš‘æœŸç®—æ³•è®­ç»ƒè¥åœ†æ»¡ç»“æŸï¼Œæ¥è‡ªå…¨å›½å„åœ°çš„60åå­¦ç”Ÿå‚åŠ äº†æ­¤æ¬¡è®­ç»ƒè¥ã€‚è®­ç»ƒè¥é‚€è¯·äº†å¤šä½çŸ¥åæ•™æˆå’Œå·¥ç¨‹å¸ˆæˆè¯¾ï¼Œå†…å®¹æ¶µç›–åŸºç¡€ç®—æ³•ã€é«˜çº§æ•°æ®ç»“æ„ã€å›¾è®ºç­‰å¤šä¸ªæ–¹é¢ã€‚',
                    'formatted_date': '2024å¹´8æœˆ5æ—¥',
                    'date': '2024-08-05',
                    'type': 'training',
                    'status': 'published'
                },
                {
                    'id': 5,
                    'title': 'å®éªŒå®¤å­¦ç”Ÿåœ¨å…¨å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ›ä¸­è·å¾—ä¸€ç­‰å¥–',
                    'excerpt': 'åœ¨åˆšåˆšç»“æŸçš„å…¨å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ›ä¸­ï¼Œå®éªŒå®¤å­¦ç”Ÿå›¢é˜Ÿå‡­å€Ÿä¼˜ç§€çš„å»ºæ¨¡èƒ½åŠ›å’Œç®—æ³•å®ç°ï¼Œè·å¾—å…¨å›½ä¸€ç­‰å¥–çš„ä¼˜å¼‚æˆç»©ï¼Œè¿™æ˜¯å­¦æ ¡è¿ç»­ç¬¬ä¸‰å¹´åœ¨è¯¥èµ›äº‹ä¸­è·å¾—å…¨å›½ä¸€ç­‰å¥–ã€‚',
                    'formatted_date': '2024å¹´9æœˆ10æ—¥',
                    'date': '2024-09-10',
                    'type': 'award',
                    'status': 'published'
                }
            ]
            print(f"ğŸ”§ Vercelç¯å¢ƒï¼šè¿”å›å®éªŒå®¤åŠ¨æ€Mockæ•°æ® {len(mock_activities)} æ¡")
            return jsonify(mock_activities)
        
        # æœ¬åœ°ç¯å¢ƒï¼šæ­£å¸¸æ•°æ®åº“æŸ¥è¯¢
        with get_db() as conn:
            cursor = conn.execute('''
                SELECT id, title, excerpt, created_at, type, status 
                FROM notifications 
                WHERE status = 'published' 
                ORDER BY created_at DESC 
                LIMIT 10
            ''')
            activities = cursor.fetchall()
            
            # è½¬æ¢æ•°æ®æ ¼å¼
            activities_data = []
            for activity in activities:
                activity_dict = dict(activity)
                # æ ¼å¼åŒ–æ—¥æœŸ
                try:
                    date_obj = datetime.fromisoformat(activity_dict['created_at'])
                    activity_dict['formatted_date'] = date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥')
                    activity_dict['date'] = date_obj.strftime('%Y-%m-%d')
                except:
                    activity_dict['formatted_date'] = 'æœªçŸ¥æ—¥æœŸ'
                    activity_dict['date'] = '2024-01-01'
                
                activities_data.append(activity_dict)
            
            return jsonify(activities_data)
    except Exception as e:
        print(f"Error fetching frontend activities: {e}")
        return jsonify({'error': str(e)}), 500

@notifications_bp.route('', methods=['GET'])
def get_notifications():
    """è·å–é€šçŸ¥åˆ—è¡¨"""
    try:
        conn = get_db()
        cursor = conn.execute('''
            SELECT * FROM notifications 
            ORDER BY order_index ASC, publish_date DESC
        ''')
        notifications = [dict(row) for row in cursor.fetchall()]
        return jsonify(notifications)
    except Exception as e:
        print(f"Error fetching notifications: {e}")
        return jsonify({"error": "è·å–é€šçŸ¥åˆ—è¡¨å¤±è´¥"}), 500

@notifications_bp.route('/<int:notification_id>', methods=['GET'])
def get_notification(notification_id):
    """è·å–é€šçŸ¥è¯¦æƒ…"""
    try:
        conn = get_db()
        notification = conn.execute('''
            SELECT id, title, content, raw_content, excerpt, author, category, 
                   reading_time, tags, status, source_type, source_file, 
                   word_count, view_count, card_style, publish_date, created_at, updated_at
            FROM notifications 
            WHERE id = ?
        ''', (notification_id,)).fetchone()
        
        if not notification:
            return jsonify({"error": "é€šçŸ¥ä¸å­˜åœ¨"}), 404
        
        # è½¬æ¢ä¸ºå­—å…¸
        notification_dict = dict(notification)
        
        # å¢åŠ æµè§ˆé‡
        conn.execute('UPDATE notifications SET view_count = view_count + 1 WHERE id = ?', (notification_id,))
        conn.commit()
        
        return jsonify(notification_dict), 200
        
    except Exception as e:
        print(f"Error getting notification: {e}")
        return jsonify({"error": "è·å–é€šçŸ¥è¯¦æƒ…å¤±è´¥"}), 500

@notifications_bp.route('', methods=['POST'])
def create_notification():
    """åˆ›å»ºæ–°é€šçŸ¥"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        data = request.get_json()
        
        # éªŒè¯å¿…å¡«å­—æ®µ
        if not data.get('title') or not data.get('content'):
            return jsonify({"error": "æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º"}), 400
        
        # å¤„ç†å†…å®¹ - æ£€æµ‹æ˜¯å¦ä¸ºmarkdownæ ¼å¼
        raw_content = data['content']
        
        # å¦‚æœå†…å®¹åŒ…å«markdownè¯­æ³•ï¼Œè½¬æ¢ä¸ºHTML
        if is_markdown_content(raw_content):
            html_content = markdown_to_html(raw_content)
        else:
            html_content = raw_content
            raw_content = html_content  # å¦‚æœä¸æ˜¯markdownï¼ŒåŸå§‹å†…å®¹å°±æ˜¯HTML
        
        # è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        excerpt = data.get('excerpt') or auto_generate_excerpt(html_content)
        
        # è®¡ç®—é˜…è¯»æ—¶é—´
        reading_time = data.get('reading_time') or calculate_reading_time(html_content)
        
        # è®¡ç®—å­—æ•°
        word_count = len(html_content)
        
        # å¤„ç†å¡ç‰‡æ ·å¼é…ç½®
        card_style = data.get('card_style', '')
        
        conn = get_db()
        cursor = conn.execute('''
            INSERT INTO notifications (
                title, content, raw_content, excerpt, author, category, reading_time, 
                tags, status, source_type, word_count, card_style, publish_date
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            data['title'],
            html_content,
            raw_content,
            excerpt,
            data.get('author', 'ACMç®—æ³•ç ”ç©¶å®éªŒå®¤'),
            data.get('category', 'å®éªŒå®¤åˆ¶åº¦'),
            reading_time,
            data.get('tags', ''),
            data.get('status', 'published'),
            data.get('source_type', 'online'),
            word_count,
            card_style,
            datetime.now()
        ))
        
        notification_id = cursor.lastrowid
        conn.commit()
        
        # é€šçŸ¥å‰ç«¯åˆ·æ–°åŠ¨æ€é¡µé¢
        notify_page_refresh('dynamic', {'created': True, 'notification_id': notification_id})
        
        return jsonify({"id": notification_id, "message": "é€šçŸ¥åˆ›å»ºæˆåŠŸ"}), 201
        
    except Exception as e:
        print(f"Error creating notification: {e}")
        return jsonify({"error": "åˆ›å»ºé€šçŸ¥å¤±è´¥"}), 500

def is_markdown_content(content):
    """æ£€æµ‹å†…å®¹æ˜¯å¦åŒ…å«markdownè¯­æ³•"""
    import re
    
    # æ£€æµ‹å¸¸è§çš„markdownæ ‡è®°
    markdown_patterns = [
        r'^#+\s',  # æ ‡é¢˜
        r'\*\*.*?\*\*',  # ç²—ä½“
        r'\*.*?\*',  # æ–œä½“
        r'`.*?`',  # è¡Œå†…ä»£ç 
        r'```[\s\S]*?```',  # ä»£ç å—
        r'^\s*[-*+]\s',  # æ— åºåˆ—è¡¨
        r'^\s*\d+\.\s',  # æœ‰åºåˆ—è¡¨
        r'^\s*>',  # å¼•ç”¨
        r'\[.*?\]\(.*?\)',  # é“¾æ¥
        r'!\[.*?\]\(.*?\)',  # å›¾ç‰‡
        r'\|.*?\|',  # è¡¨æ ¼
        r'^---+$',  # åˆ†éš”çº¿
    ]
    
    for pattern in markdown_patterns:
        if re.search(pattern, content, re.MULTILINE):
            return True
    
    return False

@notifications_bp.route('/<int:notification_id>', methods=['PUT'])
def update_notification(notification_id):
    """æ›´æ–°é€šçŸ¥"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        data = request.get_json()
        
        # éªŒè¯å¿…å¡«å­—æ®µ
        if not data.get('title') or not data.get('content'):
            return jsonify({"error": "æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º"}), 400
        
        # å¤„ç†å†…å®¹ - æ£€æµ‹æ˜¯å¦ä¸ºmarkdownæ ¼å¼
        raw_content = data['content']
        
        # å¦‚æœå†…å®¹åŒ…å«markdownè¯­æ³•ï¼Œè½¬æ¢ä¸ºHTML
        if is_markdown_content(raw_content):
            html_content = markdown_to_html(raw_content)
        else:
            html_content = raw_content
            raw_content = html_content  # å¦‚æœä¸æ˜¯markdownï¼ŒåŸå§‹å†…å®¹å°±æ˜¯HTML
        
        # è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        excerpt = data.get('excerpt') or auto_generate_excerpt(html_content)
        
        # è®¡ç®—é˜…è¯»æ—¶é—´
        reading_time = data.get('reading_time') or calculate_reading_time(html_content)
        
        # è®¡ç®—å­—æ•°
        word_count = len(html_content)
        
        # å¤„ç†å¡ç‰‡æ ·å¼é…ç½®
        card_style = data.get('card_style', '')
        
        conn = get_db()
        
        # æ£€æŸ¥é€šçŸ¥æ˜¯å¦å­˜åœ¨
        existing = conn.execute('SELECT id FROM notifications WHERE id = ?', (notification_id,)).fetchone()
        if not existing:
            return jsonify({"error": "é€šçŸ¥ä¸å­˜åœ¨"}), 404
        
        # æ›´æ–°é€šçŸ¥
        conn.execute('''
            UPDATE notifications 
            SET title = ?, content = ?, raw_content = ?, excerpt = ?, 
                author = ?, category = ?, reading_time = ?, tags = ?, 
                status = ?, word_count = ?, card_style = ?, updated_at = ?
            WHERE id = ?
        ''', (
            data['title'],
            html_content,
            raw_content,
            excerpt,
            data.get('author', 'ACMç®—æ³•ç ”ç©¶å®éªŒå®¤'),
            data.get('category', 'å®éªŒå®¤åˆ¶åº¦'),
            reading_time,
            data.get('tags', ''),
            data.get('status', 'published'),
            word_count,
            card_style,
            datetime.now(),
            notification_id
        ))
        
        conn.commit()
        
        # é€šçŸ¥å‰ç«¯åˆ·æ–°åŠ¨æ€é¡µé¢
        notify_page_refresh('dynamic', {'updated': True, 'notification_id': notification_id})
        
        return jsonify({"message": "é€šçŸ¥æ›´æ–°æˆåŠŸ"}), 200
        
    except Exception as e:
        print(f"Error updating notification: {e}")
        return jsonify({"error": "æ›´æ–°é€šçŸ¥å¤±è´¥"}), 500

@notifications_bp.route('/<int:notification_id>', methods=['DELETE'])
def delete_notification(notification_id):
    """åˆ é™¤é€šçŸ¥"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        conn = get_db()
        
        # æ£€æŸ¥é€šçŸ¥æ˜¯å¦å­˜åœ¨
        cursor = conn.execute('SELECT id, source_file FROM notifications WHERE id = ?', (notification_id,))
        notification = cursor.fetchone()
        
        if not notification:
            return jsonify({"error": "é€šçŸ¥ä¸å­˜åœ¨"}), 404
        
        # åˆ é™¤å…³è”çš„ä¸Šä¼ æ–‡ä»¶è®°å½•
        conn.execute('DELETE FROM uploaded_files WHERE notification_id = ?', (notification_id,))
        
        # åˆ é™¤é€šçŸ¥
        conn.execute('DELETE FROM notifications WHERE id = ?', (notification_id,))
        conn.commit()
        
        # å¦‚æœæœ‰æºæ–‡ä»¶ï¼Œå°è¯•åˆ é™¤
        if notification['source_file']:
            try:
                file_path = os.path.join(current_app.root_path, 'static', notification['source_file'])
                if os.path.exists(file_path):
                    os.remove(file_path)
            except Exception as e:
                print(f"åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {e}")
        
        # é€šçŸ¥å‰ç«¯åˆ·æ–°åŠ¨æ€é¡µé¢
        notify_page_refresh('dynamic', {'deleted': True, 'notification_id': notification_id})
        
        return jsonify({"message": "é€šçŸ¥åˆ é™¤æˆåŠŸ"})
        
    except Exception as e:
        print(f"Error deleting notification: {e}")
        return jsonify({"error": "åˆ é™¤é€šçŸ¥å¤±è´¥"}), 500

@notifications_bp.route('/reorder', methods=['POST'])
def reorder_notifications():
    """é‡æ–°æ’åºé€šçŸ¥"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        data = request.get_json()
        notification_ids = data.get('notification_ids', [])
        
        if not notification_ids:
            return jsonify({"error": "æ— æ•ˆçš„æ’åºæ•°æ®"}), 400
        
        conn = get_db()
        
        # æ›´æ–°æ’åº
        for index, notification_id in enumerate(notification_ids):
            conn.execute(
                'UPDATE notifications SET order_index = ?, updated_at = ? WHERE id = ?',
                (index, datetime.now(), notification_id)
            )
        
        conn.commit()
        
        # é€šçŸ¥å‰ç«¯åˆ·æ–°åŠ¨æ€é¡µé¢
        notify_page_refresh('dynamic', {'reordered': True})
        
        return jsonify({"message": "æ’åºä¿å­˜æˆåŠŸ"})
        
    except Exception as e:
        print(f"Error reordering notifications: {e}")
        return jsonify({"error": "ä¿å­˜æ’åºå¤±è´¥"}), 500

@notifications_bp.route('/upload', methods=['POST'])
def upload_document():
    """ä¸Šä¼ æ–‡æ¡£å¹¶è‡ªåŠ¨å¤„ç†"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        # æ£€æŸ¥æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400
        
        file = request.files['file']
        title = request.form.get('title', '').strip()
        category = request.form.get('category', 'å®éªŒå®¤åˆ¶åº¦')
        
        if not file or file.filename == '':
            return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400
        
        if not title:
            return jsonify({"error": "æ ‡é¢˜ä¸èƒ½ä¸ºç©º"}), 400
        
        if not allowed_doc_file(file.filename):
            return jsonify({"error": "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"}), 400
        
        # ä¿å­˜æ–‡ä»¶
        upload_dir = ensure_upload_dir()
        filename = secure_filename(file.filename)
        unique_filename = f"{uuid.uuid4()}_{filename}"
        file_path = os.path.join(upload_dir, unique_filename)
        file.save(file_path)
        
        # è·å–æ–‡ä»¶ç±»å‹
        if '.' not in filename:
            return jsonify({"error": "æ–‡ä»¶åå¿…é¡»åŒ…å«æ‰©å±•å"}), 400
        
        file_parts = filename.rsplit('.', 1)
        if len(file_parts) < 2:
            return jsonify({"error": "æ— æ•ˆçš„æ–‡ä»¶æ ¼å¼"}), 400
        
        file_type = file_parts[1].lower()
        
        # å¤„ç†æ–‡æ¡£å†…å®¹ï¼ˆåªæ”¯æŒMarkdownï¼‰
        print(f"å¼€å§‹å¤„ç†Markdownæ–‡æ¡£")
        content = extract_text_from_markdown(file_path)
        
        if not content:
            # æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
            if os.path.exists(file_path):
                os.remove(file_path)
            return jsonify({"error": "æ–‡æ¡£å†…å®¹è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–å†…å®¹"}), 400
        
        # å¤„ç†å†…å®¹æ ¼å¼
        raw_content = content
        html_content = markdown_to_html(content)
        
        # ç”Ÿæˆæ‘˜è¦å’Œè®¡ç®—é˜…è¯»æ—¶é—´
        excerpt = auto_generate_excerpt(html_content)
        reading_time = calculate_reading_time(html_content)
        word_count = len(html_content)
        
        # å¤„ç†å¡ç‰‡æ ·å¼é…ç½®ï¼ˆä»è¡¨å•æ•°æ®è·å–ï¼Œå¦‚æœæœ‰çš„è¯ï¼‰
        card_style = request.form.get('card_style', '')
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        conn = get_db()
        cursor = conn.execute('''
            INSERT INTO notifications (
                title, content, raw_content, excerpt, author, category, reading_time,
                status, source_type, source_file, word_count, card_style, publish_date
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            title,
            html_content,
            raw_content,
            excerpt,
            'ACMç®—æ³•ç ”ç©¶å®éªŒå®¤',
            category,
            reading_time,
            'published',
            'upload',
            f'uploads/notifications/{unique_filename}',
            word_count,
            card_style,
            datetime.now()
        ))
        
        notification_id = cursor.lastrowid
        
        # è®°å½•ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
        conn.execute('''
            INSERT INTO uploaded_files (
                stored_filename, original_filename, file_size, notification_id, upload_status
            ) VALUES (?, ?, ?, ?, ?)
        ''', (
            unique_filename,
            filename,
            os.path.getsize(file_path),
            notification_id,
            'success'
        ))
        
        conn.commit()
        
        return jsonify({
            "id": notification_id,
            "message": "æ–‡æ¡£ä¸Šä¼ å¤„ç†æˆåŠŸ",
            "word_count": word_count,
            "reading_time": reading_time
        }), 201
        
    except Exception as e:
        print(f"Error uploading document: {e}")
        # æ¸…ç†å¯èƒ½çš„ä¸´æ—¶æ–‡ä»¶
        if 'file_path' in locals() and os.path.exists(file_path):
            os.remove(file_path)
        return jsonify({"error": "æ–‡æ¡£ä¸Šä¼ å¤„ç†å¤±è´¥"}), 500 

@notifications_bp.route('/upload_image', methods=['POST'])
def upload_image():
    """ä¸Šä¼ å›¾ç‰‡ç”¨äºmarkdownç¼–è¾‘å™¨"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        if 'image' not in request.files:
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©å›¾ç‰‡"}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©å›¾ç‰‡"}), 400
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not allowed_image_file(file.filename):
            return jsonify({"error": "ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼"}), 400
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        filename = secure_filename(file.filename)
        name, ext = os.path.splitext(filename)
        unique_filename = f"img_{uuid.uuid4().hex}{ext}"
        
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        upload_dir = ensure_upload_dir()
        images_dir = os.path.join(upload_dir, 'images')
        os.makedirs(images_dir, exist_ok=True)
        
        file_path = os.path.join(images_dir, unique_filename)
        
        # ä¿å­˜æ–‡ä»¶
        file.save(file_path)
        
        # è¿”å›å›¾ç‰‡URL
        image_url = f'/static/uploads/notifications/images/{unique_filename}'
        
        return jsonify({
            'success': True,
            'url': image_url,
            'filename': unique_filename,
            'message': 'å›¾ç‰‡ä¸Šä¼ æˆåŠŸ'
        })
        
    except Exception as e:
        print(f"Error uploading image: {e}")
        return jsonify({"error": "å›¾ç‰‡ä¸Šä¼ å¤±è´¥"}), 500

def allowed_image_file(filename):
    """æ£€æŸ¥æ˜¯å¦ä¸ºå…è®¸çš„å›¾ç‰‡æ–‡ä»¶"""
    if '.' not in filename:
        return False
    ext = filename.rsplit('.', 1)[1].lower()
    return ext in {'png', 'jpg', 'jpeg', 'gif', 'webp', 'bmp', 'svg'}

@notifications_bp.route('/upload_card_image', methods=['POST'])
def upload_card_image():
    """ä¸Šä¼ å¡ç‰‡èƒŒæ™¯å›¾ç‰‡"""
    if not require_auth():
        return jsonify({"error": "æœªæˆæƒ"}), 401
    
    try:
        if 'image' not in request.files:
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©å›¾ç‰‡"}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©å›¾ç‰‡"}), 400
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not allowed_image_file(file.filename):
            return jsonify({"error": "ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼"}), 400
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        filename = secure_filename(file.filename)
        name, ext = os.path.splitext(filename)
        unique_filename = f"card_{uuid.uuid4().hex}{ext}"
        
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        upload_dir = ensure_upload_dir()
        cards_dir = os.path.join(upload_dir, 'cards')
        os.makedirs(cards_dir, exist_ok=True)
        
        file_path = os.path.join(cards_dir, unique_filename)
        
        # ä¿å­˜æ–‡ä»¶
        file.save(file_path)
        
        # è¿”å›å›¾ç‰‡URL
        image_url = f'/static/uploads/notifications/cards/{unique_filename}'
        
        return jsonify({
            'success': True,
            'url': image_url,
            'filename': unique_filename,
            'message': 'å¡ç‰‡èƒŒæ™¯å›¾ç‰‡ä¸Šä¼ æˆåŠŸ'
        })
        
    except Exception as e:
        print(f"Error uploading card image: {e}")
        return jsonify({"error": "å¡ç‰‡èƒŒæ™¯å›¾ç‰‡ä¸Šä¼ å¤±è´¥"}), 500 

def extract_text_from_markdown(file_path):
    """ä»Markdownæ–‡ä»¶æå–æ–‡æœ¬"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()
    except Exception as e:
        print(f"Markdownè§£æé”™è¯¯: {e}")
        return None

def is_markdown_content(content):
    """æ£€æµ‹å†…å®¹æ˜¯å¦åŒ…å«Markdownè¯­æ³•"""
    if not content:
        return False
    
    # æ£€æŸ¥å¸¸è§çš„Markdownè¯­æ³•
    markdown_patterns = [
        r'^#{1,6}\s',  # æ ‡é¢˜
        r'\*\*.*?\*\*',  # ç²—ä½“
        r'\*.*?\*',  # æ–œä½“
        r'`.*?`',  # è¡Œå†…ä»£ç 
        r'```[\s\S]*?```',  # ä»£ç å—
        r'^\s*[-*+]\s',  # æ— åºåˆ—è¡¨
        r'^\s*\d+\.\s',  # æœ‰åºåˆ—è¡¨
        r'\[.*?\]\(.*?\)',  # é“¾æ¥
        r'!\[.*?\]\(.*?\)',  # å›¾ç‰‡
        r'^\s*>\s',  # å¼•ç”¨
        r'^\|.*\|$',  # è¡¨æ ¼
        r'^\s*---+\s*$',  # åˆ†å‰²çº¿
    ]
    
    for pattern in markdown_patterns:
        if re.search(pattern, content, re.MULTILINE):
            return True
    
    return False

def auto_generate_excerpt(content, max_length=200):
    """è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦"""
    if not content:
        return ""
    
    # ç§»é™¤Markdownæ ‡è®°
    text = re.sub(r'[#*`_~\[\]()]', '', content)
    text = re.sub(r'\n+', ' ', text)
    text = text.strip()
    
    if len(text) <= max_length:
        return text
    
    # å°è¯•åœ¨å¥å·å¤„æˆªæ–­
    sentences = text.split('ã€‚')
    excerpt = ""
    for sentence in sentences:
        if len(excerpt + sentence + 'ã€‚') <= max_length:
            excerpt += sentence + 'ã€‚'
        else:
            break
    
    if not excerpt:
        excerpt = text[:max_length] + '...'
    
    return excerpt

def calculate_reading_time(content):
    """è®¡ç®—é˜…è¯»æ—¶é—´ï¼ˆæŒ‰300å­—/åˆ†é’Ÿï¼‰"""
    if not content:
        return 1
    
    # è®¡ç®—å­—æ•°ï¼ˆä¸­æ–‡å­—ç¬¦+è‹±æ–‡å•è¯ï¼‰
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
    english_words = len(re.findall(r'\b[a-zA-Z]+\b', content))
    
    total_chars = chinese_chars + english_words
    reading_time = max(1, round(total_chars / 300))
    
    return reading_time 